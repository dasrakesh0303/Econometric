summary(s2)
summary(s3)
Regx<-dynlm(loans1~L(wage1,0:18)+L(PCE1,0:18)+sealoans,start = c(2002,8))
summary(Regx)
anova(Regx,Reg2,test="F")
library(lmtest)
bgtest(Reg2,order=1)
bgtest(Reg2,order=2)
bgtest(Reg2,order=3)
bgtest(Reg2,order=4)
bgtest(Reg2,order=5)
bgtest(Reg2,order=6)
library(lmtest)
bgtest(RegY,order=1)
bgtest(RegY,order=2)
bgtest(RegY,order=3)
bgtest(RegY,order=4)
bgtest(RegY,order=5)
bgtest(RegY,order=6)
Reg11<-dynlm(loans1~L(wage1,0:22),start = c(2002,8))
anova(Reg11,RegY,test="F")
Reg12<-dynlm(loans1~L(PCE1,0:20),start = c(2002,8))
anova(Reg12,RegY,test="F")
summary(Reg2)
#
# Consumer spending data -
# Quarterly data on UK expenditures 1963:1 to 2008:4
library("tseries")
library("urca")
library("forecast")
source(file="intord.R")
library("dynlm")
library("lmtest")
df = read.csv("conspend.csv")
dfts = ts(df, start=c(1963,1), frequency=4)
plot.ts(dfts)
lcloth = log(dfts[,3]) # clothing and footwear exp.
lcloth = window(lcloth,end=c(2005,4)) # removing 3 years (12 obs)
Acf(lcloth)
Pacf(lcloth)
#unit root test
intord(lcloth)
yt=ur.df(lcloth, type="trend",selectlags="BIC")
summary(yt)
# Detrend and deseasonalize
dummies = seasonaldummy(lcloth)
res1 = dynlm(lcloth~trend(lcloth)+dummies+L(lcloth,4)+L(lcloth,8)+L(lcloth,12))
summary(res1)
intord(res1$residuals)
Acf(res1$residuals)
Pacf(res1$residuals)
n=length(lcloth)
tr = (1:n)/4
res1b = dynlm(lcloth~tr+dummies+L(lcloth,4)+L(lcloth,8)+L(lcloth,12))
summary(res1b)
res=auto.arima(lcloth)
res
Acf(lcloth)
Pacf(lcloth) # unit root problem
dlcloth = diff(lcloth) # difference with previous quarter (solve unit root problem)
sddlcloth = diff(dlcloth,4) # difference with previous year (solve unit root problem on seasonal lags)
Acf(dlcloth)
Pacf(dlcloth)
Acf(sddlcloth)
Pacf(sddlcloth)
#estimate ARIMA model
arma1 = arima(lcloth,order=c(1,1,1),seasonal=c(1,1,1))
arma1
arma2 = arima(lcloth,order=c(0,1,0),seasonal=c(1,1,1))
arma2
arma3 = arima(lcloth,order=c(0,1,1),seasonal=c(1,1,1))
arma3
res # auto.arima function - optimal results
Acf(res$residuals)
Pacf(res$residuals)
Acf(arma2$residuals) # still have spikes for MA(1)
Pacf(arma2$residuals) # still have spikes for AR(1)
arma4 = arima(lcloth,order=c(1,1,0),seasonal=c(1,1,1))
arma4
Acf(arma4$residuals)
Pacf(arma4$residuals)
# diagnostics for residuals
tsdiag(arma4)
# BoX-Ljung Q Statistic
b = Box.test(arma4$residuals,lag = 20, type="Ljung-Box")
b
blt = rep(0,20)
for (i in 1:20){
b = Box.test(arma4$residuals,lag = i, type="Ljung-Box")
blt[i]=b$p.value
}
blt
#
# Out-of-sample forecasting h-steps ahead (dynamic)
#
h = 12 #(3 years ahead)
n = length(lcloth)
nh = n + h
#create a trend
trt = (1:nh)/4
arma4 = arima(lcloth,order=c(1,1,0),seasonal=c(1,1,1))
#forecasting
fcast = predict(arma4,n.ahead=12)
#plot
ts.plot(lcloth,fcast$pred,col=1:2)
abline(v=2006)
accuracy(arma4)
summary(res)
##
# compare with auto arima
##
arma5 = arima(lcloth,order=c(0,1,1),seasonal=c(1,1,1))
#forecasting
fcast5 = predict(arma5,n.ahead=12)
#plot
ts.plot(lcloth,fcast5$pred,col=1:2)
abline(v=2006)
accuracy(arma5)
#####################################
#########################################
########################################
#
# Introduce trend and seasonal dummies in forecasting
#
#create a trend
trt = (1:nh)/4
trf = trt[(n+1):nh]
sdum = seasonaldummy(ts(rep(0,nh),start=c(1963,1),frequency=4))
sdumf = sdum[(n+1):nh,]
tr=(1:n)/4
xx=cbind(sdum[1:n,],tr)
#arma5 = arima(lcloth,order=c(1,1,0),seasonal=c(1,1,1),xreg=xx)
#arma5 # remove I(1)
arma6 = arima(lcloth,order=c(1,0,0),seasonal=c(1,0,1),xreg=xx)
arma6
Acf(arma6$residuals) #
Pacf(arma6$residuals)
xxf = cbind(sdumf,trf)
fcast6 = predict(arma6,n.ahead=12,newxreg=xxf)
ts.plot(lcloth,fcast6$pred,col=1:2)
abline(v=2006)
#create a trend
trt = (1:nh)/4
trf = trt[(n+1):nh]
sdum = seasonaldummy(ts(rep(0,nh),start=c(1963,1),frequency=4))
sdumf = sdum[(n+1):nh,]
tr=(1:n)/4
xx=sdum[1:n,]
arma7 = arima(lcloth,order=c(1,0,0),seasonal=c(1,0,1),xreg=xx)
arma7
xxf = sdumf
fcast7 = predict(arma7,n.ahead=12,newxreg=xxf)
ts.plot(lcloth,fcast7$pred,col=1:2)
abline(v=2006)
arma9 = arima(lcloth,order=c(1,0,0),seasonal=c(1,0,1))
arma9
Acf(arma9$residuals) #
Pacf(arma9$residuals)
xx=tr
arma8 = arima(lcloth,order=c(1,0,0),seasonal=c(1,0,1),xreg=xx)
arma8
xxf = trf
fcast8 = predict(arma8,n.ahead=12,newxreg=xxf)
ts.plot(lcloth,fcast8$pred,col=1:2)
abline(v=2006)
arma7
# ARMA Processes
#
# AR(1) Process
#
set.seed(123)
n=1000
sig2 = 0.5
phi=0.9
e= sqrt(sig2)*rnorm(n) # error terms
y=rep(0,n)
y[1]=e[1]# first observation
for (t in 2:n){
y[t]=1+phi*y[t-1]+e[t]
}
source(file="intord.R")
intord(y)
acf(y)
pacf(y)
p=1
d=0
q=0
arima1 = arima(y,order=c(p,d,q))
arima1
#Coefficients:
#  ar1  intercept
#0.3635     1.6819
#s.e.  0.0296     0.0349
# the value 1.6818 is E(y) = mu/(1-phi)=1/(0.6)=1.67
# Unit root Process
set.seed(123)
n=10000
sig2 = 0.5
phi=1
e= sqrt(sig2)*rnorm(n) # error terms
y=rep(0,n)
y[1]=e[1]# first observation
for (t in 2:n){
y[t]=1+phi*y[t-1]+e[t]
}
source(file="intord.R")
intord(y)
acf(y)
pacf(y)
p=1
d=1
q=0
arima2 = arima(y,order=c(p,d,q))
arima2
arima3 = arima(diff(y),order=c(1,0,0))
arima3
arima4 = arima(y,order=c(1,1,0),xreg=1:length(y))
arima4
# AR-MAprocess.R
# generate AR(1), AR(2), MA(1) and MA(2) processes
# plot SACF and SPACF for each process
# see ar1sim.R for AR(1) process
# clear the workspace
rm(list = ls())
# AR(2) process
phi1 <- 0.4
phi2 <- 0.3
sig2 <- 0.5
set.seed(128)
n <- 1000
e <- sqrt(sig2)*rnorm(n)
y <- rep(0,n)
y[1] <- e[1]
y[2] <- phi1*y[1] + e[2]
for (t in 3:n) {
y[t] <- phi1*y[t-1] + phi2*y[t-2] + e[t]
}
par(mfrow=c(2,2))
plot(y[200:300],type='l',col=4,lwd=2)
plot(e[200:300],type='l',col=1,lwd=2)
acf(y,lwd=3,col=3)
pacf(y,lwd=3,col=3)
Acf(y)
Pacf(y)
############# combined AR + MA = ARMA processes next
# ARMA(1,1) process
# y = phi*y(t-1) + e(t) + theta*e(t-1)
theta <- 0.6
phi <- -0.3
y <- rep(0,n)
y[1] <- e[1]
for (t in 2:n) {
y[t] <- phi*y[t-1] + e[t] + theta*e[t-1]
}
par(mfrow=c(2,2))
plot(y[200:300],type='l',col=4,lwd=2)
plot(e[200:300],type='l',col=1,lwd=2)
acf(y,lwd=3,col=3)
pacf(y,lwd=3,col=3)
res= auto.arima(y)
res
p <- 5
d <- 0
q <- 2
arma <- arima(y, order = c(p,d,q))
arma
res <- arma$residuals
source(file="intord.R")
intord(res)
p <- 1
d <- 0
q <- 2
arma <- arima(y, order = c(p,d,q))
arma
res <- arma$residuals
source(file="intord.R")
intord(res)
# AR(1) proces
phi1 <- 0.4
sig2 <- 0.5
set.seed(128)
n <- 1000
e <- sqrt(sig2)*rnorm(n)
y <- rep(0,n)
y[1] <- e[1]
for (t in 3:n) {
y[t] <- 2+phi1*y[t-1]  + e[t]
}
arima = arima(y,order = c(1,0,0)) #intercept is 0.4/(1-phi)
arima
# unit root process
phi1 <- 1
sig2 <- 0.5
set.seed(128)
n <- 1000
e <- sqrt(sig2)*rnorm(n)
y <- rep(0,n)
y[1] <- e[1]
for (t in 3:n) {
y[t] <- 1+phi1*y[t-1]  + e[t]
}
res= auto.arima(y)
res
arima = arima(y,order = c(2,1,0)) #
arima
arima2 = arima(diff(y),order = c(2,0,0)) #
arima2
arima3 = arima(y,order = c(2,1,0),xreg=1:length(y)) #
arima3
# unit root process
phi1 <- .95
sig2 <- 0.5
set.seed(128)
n <- 1000
e <- sqrt(sig2)*rnorm(n)
y <- rep(0,n)
y[1] <- e[1]
for (t in 3:n) {
y[t] <- 1+phi1*y[t-1]  + e[t]
}
res= auto.arima(y)
res
arima = arima(y,order = c(2,0,1)) #
arima
arima2 = arima(y,order = c(1,0,1)) #
arima2
arima3 = arima(y,order = c(1,0,0)) #
arima3
library("dynlm")
library("forecast")
library("tseries")
library("quantmod")
library("stats")
library("urca")
source(file="intord.R")
df1<-read.csv("wage and salary.csv")
df2<-read.csv("consumer loans.csv")
df3<-read.csv("PCE.csv")
wage<-ts(df1[,2],frequency = 12,start = c(2000,07))
loans<-ts(df2[,2],frequency = 12,start = c(2000,07))
PCE<-ts(df3[,2],frequency = 12,start = c(2000,07))
#stationarity
waget=ur.df(wage,type="trend",selectlags = "BIC")
summary(waget)
intord(wage)
wage1<-diff(wage)
wage1t=ur.df(wage1,type="trend",selectlags = "BIC")
summary(wage1t)
loanst<-ur.df(loans,type="trend",selectlags = "BIC")
summary(loanst)
intord(loans)
loans1<-diff(loans)
loans1t<-ur.df(loans1,type="trend",selectlags = "BIC")
summary(loans1t)
PCEt<-ur.df(PCE,type="trend",selectlags = "BIC")
summary(PCEt)
intord(PCE)
PCE1<-diff(PCE)
PCE1t<-ur.df(PCE1,type="trend",selectlags = "BIC")
summary(PCE1t)
#first difference for everyone
#dynamic regression
Reg1<-dynlm(loans1~L(loans1,1:24)+L(wage1,0:24)+L(PCE1,0:24))
summary(Reg1)
seawage<-seasonaldummy(wage1)
s1<-dynlm(wage1~seawage)
sealoans<-seasonaldummy(loans1)
s2<-dynlm(loans1~sealoans)
seapce<-seasonaldummy(PCE1)
s3<-dynlm(PCE1~seapce)
summary(s1)
summary(s2)
summary(s3)
Regx<-dynlm(loans1~L(wage1,0:18)+L(PCE1,0:18)+sealoans,start = c(2002,8))
summary(Regx)
anova(Regx,Reg2,test="F")
library(lmtest)
bgtest(Reg2,order=1)
bgtest(Reg2,order=2)
bgtest(Reg2,order=3)
bgtest(Reg2,order=4)
bgtest(Reg2,order=5)
bgtest(Reg2,order=6)
library(lmtest)
bgtest(RegY,order=1)
bgtest(RegY,order=2)
bgtest(RegY,order=3)
bgtest(RegY,order=4)
bgtest(RegY,order=5)
bgtest(RegY,order=6)
Reg11<-dynlm(loans1~L(wage1,0:22),start = c(2002,8))
anova(Reg11,RegY,test="F")
library("dynlm")
library("forecast")
library("tseries")
library("quantmod")
library("stats")
library("urca")
source(file="intord.R")
df1<-read.csv("wage and salary.csv")
df2<-read.csv("consumer loans.csv")
df3<-read.csv("PCE.csv")
wage<-ts(df1[,2],frequency = 12,start = c(2000,07))
loans<-ts(df2[,2],frequency = 12,start = c(2000,07))
PCE<-ts(df3[,2],frequency = 12,start = c(2000,07))
#stationarity
waget=ur.df(wage,type="trend",selectlags = "BIC")
summary(waget)
intord(wage)
wage1<-diff(wage)
wage1t=ur.df(wage1,type="trend",selectlags = "BIC")
summary(wage1t)
library("dynlm")
library("forecast")
library("tseries")
library("quantmod")
library("stats")
library("urca")
source(file="intord.R")
df1<-read.csv("wage and salary.csv")
df2<-read.csv("consumer loans.csv")
df3<-read.csv("PCE.csv")
wage<-ts(df1[,2],frequency = 12,start = c(2000,07))
loans<-ts(df2[,2],frequency = 12,start = c(2000,07))
PCE<-ts(df3[,2],frequency = 12,start = c(2000,07))
#stationarity
waget=ur.df(wage,type="trend",selectlags = "BIC")
summary(waget)
intord(wage)
wage1<-diff(wage)
wage1t=ur.df(wage1,type="trend",selectlags = "BIC")
summary(wage1t)
loanst<-ur.df(loans,type="trend",selectlags = "BIC")
summary(loanst)
intord(loans)
loans1<-diff(loans)
loans1t<-ur.df(loans1,type="trend",selectlags = "BIC")
summary(loans1t)
PCEt<-ur.df(PCE,type="trend",selectlags = "BIC")
summary(PCEt)
intord(PCE)
PCE1<-diff(PCE)
PCE1t<-ur.df(PCE1,type="trend",selectlags = "BIC")
summary(PCE1t)
#first difference for everyone
#dynamic regression
Reg1<-dynlm(loans1~L(loans1,1:24)+L(wage1,0:24)+L(PCE1,0:24))
summary(Reg1)
#0 #18 #18 #2002,8
Reg2<-dynlm(loans1~L(wage1,0:18)+L(PCE1,0:18),start = c(2002,8))
summary(Reg2)
AIC(Reg1)
BIC(Reg1)
AIC(Reg2)
BIC(Reg2)
#seasonality
seawage<-seasonaldummy(wage1)
s1<-dynlm(wage1~seawage)
sealoans<-seasonaldummy(loans1)
s2<-dynlm(loans1~sealoans)
seapce<-seasonaldummy(PCE1)
s3<-dynlm(PCE1~seapce)
summary(s1)
summary(s2)
summary(s3)
Regx<-dynlm(loans1~L(wage1,0:18)+L(PCE1,0:18)+sealoans,start = c(2002,8))
summary(Regx)
anova(Regx,Reg2,test="F") #cannot reject the null dummy avoid
library(lmtest)
bgtest(Reg2,order=1)
bgtest(Reg2,order=2)
bgtest(Reg2,order=3)
bgtest(Reg2,order=4)
bgtest(Reg2,order=5)
bgtest(Reg2,order=6)
summary(wage1t)
loanst<-ur.df(loans,type="trend",selectlags = "BIC")
summary(loanst)
intord(loans)
loans1t<-ur.df(loans1,type="trend",selectlags = "BIC")
summary(loans1t)
#first difference for everyone
#dynamic regression
Reg1<-dynlm(loans1~L(loans1,1:24)+L(wage1,0:24)+L(PCE1,0:24))
summary(Reg1)
#0 #18 #18 #2002,8
Reg2<-dynlm(loans1~L(wage1,0:18)+L(PCE1,0:18),start = c(2002,8))
summary(Reg2)
AIC(Reg1)
#seasonality
seawage<-seasonaldummy(wage1)
s1<-dynlm(wage1~seawage)
s2<-dynlm(loans1~sealoans)
seapce<-seasonaldummy(PCE1)
s3<-dynlm(PCE1~seapce)
summary(s1)
summary(s2)
summary(s3)
summary(s2)
Regx<-dynlm(loans1~L(wage1,0:18)+L(PCE1,0:18)+sealoans,start = c(2002,8))
summary(Regx)
anova(Regx,Reg2,test="F") #cannot reject the null dummy avoid
library(lmtest)
bgtest(Reg2,order=1)
bgtest(Reg2,order=2)
bgtest(Reg2,order=3)
bgtest(Reg2,order=4)
bgtest(Reg2,order=5)
bgtest(Reg2,order=6)
summary(s1)
summary(s2)
summary(s3)
